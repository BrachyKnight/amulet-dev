# AMULET
<!-- ABOUT THE PROJECT -->
## About The Project
AMULET (Analysis MUon LifETime) consists in a series of C++ and python scripts written to analyze data relative to the life-times of cosmic muons.
The project has two main parts:
* Reading data taken with a caen digitizer (CAEN DT5751). This is the most important part and it is actually the main focus of this project.
* Analyze data to produce plots, perform fit, and do everything is needed to measure in the most accurate way the lifetime of cosmic muons decaying both in carbon (scintillator material) and other materials. 

<!-- GETTING STARTED -->
## Getting Started
Using thes script is simple!

First of all ensure to have the proper prerequisites, otherwise install them.
Download all the project and compile the script by executing the ./compile_scripts.sh script that is present in the folder called digitizer_scripts/

There are really only two things that is important that you do properly
* Using the correct prerequisites (in particular ROOT)
* **Work using the correct directories and the correct naming schemes for your files!**

In order to understand how to use the code you have to know something about the experiment:
* muon lifetime is measured using an array of three overlapped plastic scintillators
* the analogic signals from the photomultipliers are converted in fast NIM negative standard signals using a CFD.
* the logic signal pass through a trigger circuit (the most difficult part of the experiment is to realize this) that as output provide:
  * one trigger NIM to trig the digitizer to aquire the waveform
  * two signals that are aquired in the channel0 and channel1 of the digitizer, these are the waveform that the code in this project is meant to analyze

### Prerequisites
* [ROOT CERN toolkit](https://root.cern/): this project is based on ROOT and, in particular, it uses RDataFrames to generate .root files containing TTree with all the relevant quantities that can be extracted from xml RAW data. Since when I developed the project (2021) RDataFrames and VecOps::RVec where under construction it is particularly important that, if you encounter problems, you install the same version I used: **ROOT v6.24/00**.
* python3
* lxml module of python3
  ```
  pip3 install lxml
  ```

<!-- USAGE EXAMPLES -->
## Usage
After having downloaded the project and compiled all the C++ script using the lines of code in ./compile_scripts.sh
1. Ensure to have the correct naming scheme for your files (runXmeasY.xml where X=run number and Y = meas number). These xml data are meant to be the ones (or equivalent to) the ones generated by CAENSCOPE taken with the digitizer DT5751;
2. Ensure to have the exact directories and subdirectories contained in the git hub project;
3. Go to the digitizer_scripts/ folder and from here you can start to work on your data:
  - Copy yout xml data files in the DAQERM/ folder;
  - **Open the file logicSignalAnalysis.cpp and set the sampling frequency that you have used** (int sampfreq = XXX, change XXX with your sampling frequency es.: 1e09). If you forget this step everything will work fine but you have to keep in mind that the time that you will see on the X-Axis of your plots have to be converted with a conversion factor depending on the ratio between the sampfreq that is set and the one that you have actually used.
  - Recompile the scripts to have consistent results ```
  ./compile_scripts.sh```
  - You can choose to process all the measurements in one run by launching ```
  ./preprocess_entire_run RUNNUMBER ../DAQERM ```
  and this command will launch two scripts:
    - xmltoTTreeRDF will perform a copy of the data contained in the xml file into the .root files in the folder DAQpreprocessed/ . The output file contains a TTree with the amplitudes that the oscilloscope have measured, this is pretty useless but it is a starting point to process the data with ROOT. **WARNING: this script will implicitly launch the python script called xmltotree.py which makes use of the python class DT5751ReadPersonalized.py which have a bug that fills up RAM memory of your PC if the xml file is too big _contact me for me for more info, but you encouraged to find another way to manage all this part_**
    - logicSignalAnalysis will update the just created .root file and it will add the following information
      - the time coordinates of the waveforms collected with the first script in a TTree called amulet. You can now see the waveforms using ROOT (for example by opening the .root file and calling ```amulet->Draw("ch0_wvf_amp:ch0_wvf_time","Entry$ == 1")``` this will draw the wvf of the first entry).
      - the data relative to the waveforms for the two channels (number of squares in each signal, temporal information to when the square waves arrived). You can better understand by open up the .root file in a TBrowser and plotting some ditributions. 
  - Now you have to evaluate lifetimes starting from the square wave informations: 
    - launch the third script ```./lifetime``` and it wil provide examples of what input it wants, then re-launch it again with the correct input
    - if you followed the instructions correctly the script will produce an output root file in the DAQprocessed/ folder with root file containing the decay times!!
    - you can open the file with a TBrowser and plot your distributions, there will be a lot of them but I'm sure you can figure out what they are :wink:
5. Now you can start your analysis of muon lifetime!! you can use the scripts in the folder amulet_analysis/ but they are quite buggy and they are strictly related to my set of data, so it is meant to be more like an example.

**_contact me for any question, I will more than happy to explain more in detail how the code works_**

<!-- CONTRIBUTING -->
## Contributing
This code has some serious problems, in particular in the first part (the xmltoTTree.cpp code that calls the python script to read the xml data). I would love to improve the code but I am focusing more on the analysis part. Anyway, I strongly believe that the RDataFrame/TTree-approach has a great potential, even if it is a bit overcomplicated. This method of analyzing data could lead to a better overall quality of the resut, expecially if combined with a Monte Carlo GEANT4 simulation. For these reason I would be happy if anyone will contribute to the project.
Moreover, as always, contributions are what make the open source community such an amazing place to be learn, inspire, and create. Any contributions you make are **greatly appreciated** :smile: .

1. Create your Feature Branch (`git checkout -b feature/AmazingFeature`)
2. Commit your Changes (`git commit -m 'Add some AmazingFeature'`)
3. Push to the Branch (`git push origin feature/AmazingFeature`)
4. Open a Pull Request


<!-- CONTACT -->
## Contact

Your Name - massimogirola1@gmail.com - m.girola2@campus.unimib.it

Project Link: [https://github.com/mgirola/amulet](https://github.com/mgirola/amulet)


<!-- ACKNOWLEDGEMENTS -->
## Acknowledgements
* [ROOT CERN](https://root.cern/)
* [ROOT forum](https://root-forum.cern.ch/)

